# Recommender System

## Overview

A recommender system is a machine learning model designed to suggest items, products, or content to users based on various criteria. This project implements a content-based movie recommender system that suggests movies based on their features, including overview, genres, director, actors, and keywords.

### Dataset

The dataset used in this project is complete_movie_dataset.csv, which contains 9,130 movies with the following key attributes:

- `movie_ID`: Unique identifier for each movie
- `title`: Movie title
- `overview`: Brief movie description
- `genres`: Genre classification of the movie
- `director`: Name of the movie's director
- `top_actors`: Leading actors in the movie
- `keywords`: Descriptive keywords associated with the movie

## Data Preprocessing

### Steps performed:

**1. Handling Missing Values**:

- Missing values in overview, director, top_actors, and keywords were replaced with an empty string.
- Verified that no null values remained after processing.

**2. Removing Duplicates**:

- Checked and confirmed that there were no duplicate entries in the dataset.

**3. Converting String Data to Lists**:

- genres, top_actors, and keywords were converted from string format to Python lists.

**4. Text Processing**:

- Spaces within genres, overview, director, and top_actors were removed to standardize text formatting.

**5. Feature Engineering**:

Created a new column `tags`, which is a concatenation of overview, genres, director, top_actors, and keywords. This will be used for similarity calculations.

## Recommendation System Implementation

### 1. Stemming in Movie Recommendation System

- To improve text processing, we apply stemming to reduce words to their root form. This helps in better matching of movie-related terms.

- We use `PorterStemmer` from nltk to stem keywords before vectorization.

For example:  
- *"Loved"*, *"Loving"*, and *"Love"* → **"love"**  
- *"Watching"*, *"Watches"*, and *"Watched"* → **"watch"**  

We use **NLTK’s PorterStemmer** to apply stemming.  

```python
from nltk.stem.porter import PorterStemmer

stemmer = PorterStemmer()

def stem_text(text):
    words = text.lower().split()
    stemmed_words = [stemmer.stem(word) for word in words]
    return " ".join(stemmed_words)
```

This technique eliminates inconsistencies in word forms, ensuring the recommendation system treats them as identical words. By applying stemming to the 'tags' column, the system enhances its ability to recognize and compare movies with similar themes or topics, leading to more precise and relevant movie recommendations.

### 2. Vectorization

Vectorization is the process of converting textual data into numerical vectors, enabling machine learning models to process and analyze the data. In this project, we employ two methods of vectorization:

- **Bag of Words (BoW)**: Represents text data as a matrix of token counts.
- **TF-IDF**: Reflects the importance of a word in a document relative to all other documents in the dataset. It downscales the weight of frequently occurring words.

### 3. Cosine Similarity

Once the movie descriptions or titles are vectorized, we calculate the Cosine Similarity between vectors to determine how similar the two movies are. The formula for Cosine Similarity is:

$`
\text{cosine\_similarity}(A, B) = \frac{A \cdot B}{\|A\| \|B\|}
`$

Where A and B are the vectorized representations of two movies.

### 4. TF-IDF vs Bag of Words

Both vectorization techniques have been implemented in parallel. The choice between BoW and TF-IDF is evaluated by comparing their performance using a precision metric.

- Bag of Words captures the frequency of words but doesn’t account for the importance of rare terms.
- TF-IDF adjusts the weight of words, reducing the importance of common words and highlighting unique or rare terms.

### 5. Main Function

The main function of the project ties everything together. It:

- Loads the dataset
- Preprocesses the data (tokenization, removing stopwords)
- Vectorizes the movie descriptions or titles using BoW and TF-IDF
- Calculates similarity scores
- Returns top movie recommendations based on these similarity scores

### 6. Comparison

To compare the performance of the vectorization techniques, we evaluate both BoW and TF-IDF using the precision at 10 (Precision@10) metric. We calculate the accuracy of the top 10 recommended movies for a given movie and compare it to the actual recommendations from JioCinema.

### 7. Calculating Precision

Precision at 10 is calculated by comparing the top 10 movie recommendations generated by the system to the top 10 movies from a reference dataset (e.g., JioCinema for the movie "Harry Potter"). The formula is:

$`
\text{Precision@10} = \frac{\text{Number of relevant movies in top 10}}{10}
`$

### 8. Pickling the model

After evaluating both vectorization techniques, the best-performing model is pickled and saved for later use. This allows for quick loading and prediction without the need for re-training. 

The `pickle` module is used for serializing the trained models.

















